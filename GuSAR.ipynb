{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# QSAR для антимикробных пептидомиметиков: практический ноутбук\n\nЭтот ноутбук переписан в формате **учебной боевой практики**: минимум магии, максимум воспроизводимости.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Жесткая критика исходного подхода (и почему это важно для Q1-уровня)\n\n1. **Повторяющиеся и хаотичные ячейки** → высокий риск ошибок и невоспроизводимости.\n2. **Нет строгой валидации** (иногда просто один сплит) → метрики завышаются.\n3. **Смешение EDA, feature engineering и моделирования без пайплайна** → утечки данных.\n4. **Нет Applicability Domain (AD)** → предсказания вне химического пространства ненадежны.\n5. **Нет baseline и интерпретации ошибок** → непонятно, лучше ли модель тривиального предсказания.\n\nНиже — версия, которая ближе к хорошей научной практике.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Если запускаешь локально впервые, раскомментируй:\n# !pip install rdkit-pypi scikit-learn pandas numpy matplotlib seaborn\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom rdkit import Chem, DataStructs\nfrom rdkit.Chem import AllChem, Descriptors\nfrom rdkit.ML.Descriptors import MoleculeDescriptors\n\nfrom sklearn.model_selection import RepeatedKFold, cross_validate\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import Ridge\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import make_scorer, mean_absolute_error, mean_squared_error, r2_score\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1) Загрузка и базовая очистка"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "DATA_PATH = 'potok.csv'  # ожидаются столбцы: smiles, activity\n\ndf = pd.read_csv(DATA_PATH)\nprint('Raw shape:', df.shape)\ndf.head()\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "required_cols = {'smiles', 'activity'}\nmissing = required_cols - set(df.columns)\nif missing:\n    raise ValueError(f'В файле отсутствуют обязательные столбцы: {missing}')\n\ndf = df[['smiles', 'activity']].copy()\ndf['activity'] = pd.to_numeric(df['activity'], errors='coerce')\ndf = df.dropna(subset=['smiles', 'activity'])\ndf = df[df['activity'] > 0]  # для логарифма\n\ndf['mol'] = df['smiles'].apply(Chem.MolFromSmiles)\ndf = df[df['mol'].notnull()].copy()\ndf = df.drop_duplicates(subset='smiles').reset_index(drop=True)\ndf['logACT'] = np.log10(df['activity'])\n\nprint('Clean shape:', df.shape)\ndf.head()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2) Дескрипторы: понятная функция без ручного копипаста"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "descriptor_names = [\n    'MolWt', 'MolLogP', 'NumHDonors', 'NumHAcceptors',\n    'NumHeteroatoms', 'NumRotatableBonds', 'TPSA',\n    'NumAromaticRings', 'RingCount', 'FractionCSP3'\n]\n\ncalc = MoleculeDescriptors.MolecularDescriptorCalculator(descriptor_names)\n\ndef calc_descriptor_frame(mols):\n    rows = []\n    for mol in mols:\n        vals = calc.CalcDescriptors(mol)\n        rows.append(vals)\n    return pd.DataFrame(rows, columns=descriptor_names)\n\nX_desc = calc_descriptor_frame(df['mol'])\ny = df['logACT'].to_numpy()\n\nprint('Descriptor matrix:', X_desc.shape)\nX_desc.head()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3) Morgan fingerprints (битовые признаки)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def morgan_fp_array(mol, radius=2, n_bits=2048):\n    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n    arr = np.zeros((n_bits,), dtype=np.int8)\n    DataStructs.ConvertToNumpyArray(fp, arr)\n    return arr\n\nX_fp = np.vstack([morgan_fp_array(m) for m in df['mol']])\nprint('Fingerprint matrix:', X_fp.shape)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4) Честная оценка: Repeated K-Fold + baseline"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def rmse(y_true, y_pred):\n    return np.sqrt(mean_squared_error(y_true, y_pred))\n\nscoring = {\n    'MAE': make_scorer(mean_absolute_error, greater_is_better=False),\n    'RMSE': make_scorer(rmse, greater_is_better=False),\n    'R2': make_scorer(r2_score)\n}\n\ncv = RepeatedKFold(n_splits=5, n_repeats=10, random_state=42)\n\nmodels = {\n    'Ridge_descriptors': Pipeline([\n        ('imputer', SimpleImputer(strategy='median')),\n        ('scaler', StandardScaler()),\n        ('model', Ridge(alpha=1.0))\n    ]),\n    'RF_descriptors': Pipeline([\n        ('imputer', SimpleImputer(strategy='median')),\n        ('model', RandomForestRegressor(\n            n_estimators=500,\n            random_state=42,\n            min_samples_leaf=2,\n            n_jobs=-1\n        ))\n    ]),\n    'Ridge_fingerprint': Pipeline([\n        ('imputer', SimpleImputer(strategy='most_frequent')),\n        ('scaler', StandardScaler(with_mean=False)),\n        ('model', Ridge(alpha=2.0))\n    ])\n}\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "results = []\n\ndef summarize_cv(name, model, X, y):\n    out = cross_validate(model, X, y, cv=cv, scoring=scoring, n_jobs=-1)\n    return {\n        'model': name,\n        'MAE_mean': -out['test_MAE'].mean(),\n        'MAE_std': out['test_MAE'].std(),\n        'RMSE_mean': -out['test_RMSE'].mean(),\n        'RMSE_std': out['test_RMSE'].std(),\n        'R2_mean': out['test_R2'].mean(),\n        'R2_std': out['test_R2'].std(),\n    }\n\nresults.append(summarize_cv('Ridge_descriptors', models['Ridge_descriptors'], X_desc, y))\nresults.append(summarize_cv('RF_descriptors', models['RF_descriptors'], X_desc, y))\nresults.append(summarize_cv('Ridge_fingerprint', models['Ridge_fingerprint'], X_fp, y))\n\n# baseline: среднее по train в каждом фолде (ручной расчет)\nb_mae, b_rmse, b_r2 = [], [], []\nfor train_idx, test_idx in cv.split(X_desc):\n    y_train, y_test = y[train_idx], y[test_idx]\n    pred = np.full_like(y_test, y_train.mean())\n    b_mae.append(mean_absolute_error(y_test, pred))\n    b_rmse.append(rmse(y_test, pred))\n    b_r2.append(r2_score(y_test, pred))\n\nresults.append({\n    'model': 'Baseline_mean',\n    'MAE_mean': np.mean(b_mae), 'MAE_std': np.std(b_mae),\n    'RMSE_mean': np.mean(b_rmse), 'RMSE_std': np.std(b_rmse),\n    'R2_mean': np.mean(b_r2), 'R2_std': np.std(b_r2),\n})\n\nres_df = pd.DataFrame(results).sort_values('RMSE_mean')\nres_df\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5) Applicability Domain через similarity-to-train (Tanimoto)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def tanimoto_to_train(test_mol, train_mols, radius=2, n_bits=2048):\n    fp_test = AllChem.GetMorganFingerprintAsBitVect(test_mol, radius, nBits=n_bits)\n    train_fps = [AllChem.GetMorganFingerprintAsBitVect(m, radius, nBits=n_bits) for m in train_mols]\n    sims = DataStructs.BulkTanimotoSimilarity(fp_test, train_fps)\n    return max(sims) if sims else 0.0\n\n# Демонстрация на одном CV-сплите\nfrom sklearn.model_selection import KFold\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\ntrain_idx, test_idx = next(kf.split(df))\n\ntrain_mols = df.loc[train_idx, 'mol'].tolist()\ntest_mols = df.loc[test_idx, 'mol'].tolist()\n\ntanimoto_max = [tanimoto_to_train(m, train_mols) for m in test_mols]\n\nad_demo = pd.DataFrame({\n    'smiles': df.loc[test_idx, 'smiles'].values,\n    'logACT': df.loc[test_idx, 'logACT'].values,\n    'max_train_tanimoto': tanimoto_max,\n})\nad_demo.head()\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "plt.figure(figsize=(6,4))\nsns.histplot(ad_demo['max_train_tanimoto'], bins=15)\nplt.title('Applicability Domain proxy: max train Tanimoto')\nplt.xlabel('Max Tanimoto to train set')\nplt.grid(alpha=0.3)\nplt.show()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6) Что делать дальше, чтобы приблизиться к публикации Q1\n\n- Добавить **scaffold split** и отдельно report для scaffold-out теста.\n- Выполнить **Y-randomization** (sanity check против случайных корреляций).\n- Посчитать **confidence interval** метрик (bootstrap по фолдам).\n- Сделать интерпретацию: SHAP (для RF/GBM) или importance по permutation.\n- Прописать **domain of applicability policy**: напр. max Tanimoto < 0.3 => low confidence.\n\nЕсли хочешь, следующим шагом я дам тебе учебный блок: \"ты пишешь код сам, я проверяю построчно и критикую\".\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
